{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "part3_predict.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPXY7dFCSJw8Cy5guTRocu9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/m37335/kanagawa-exam/blob/master/part3_predict.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFzLal94TxNr"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install stanza"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfIe3DVZTQwJ",
        "outputId": "80fad119-c30a-4def-c368-17a8caa77c83"
      },
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertForMaskedLM\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# stanza\n",
        "import stanza\n",
        "stanza.download('en') # download English model\n",
        "\n",
        "nlp = stanza.Pipeline(lang='en', processors='tokenize,mwt,pos,lemma', use_gpu=True, tokenize_pretokenized=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/master/resources_1.2.0.json: 128kB [00:00, 33.7MB/s]                    \n",
            "2021-05-05 03:41:52 INFO: Downloading default packages for language: en (English)...\n",
            "2021-05-05 03:41:53 INFO: File exists: /root/stanza_resources/en/default.zip.\n",
            "2021-05-05 03:41:57 INFO: Finished downloading models and saved to /root/stanza_resources.\n",
            "2021-05-05 03:41:57 WARNING: Can not find mwt: default from official model list. Ignoring it.\n",
            "2021-05-05 03:41:57 INFO: Loading these models for language: en (English):\n",
            "========================\n",
            "| Processor | Package  |\n",
            "------------------------\n",
            "| tokenize  | combined |\n",
            "| pos       | combined |\n",
            "| lemma     | combined |\n",
            "========================\n",
            "\n",
            "2021-05-05 03:41:57 INFO: Use device: gpu\n",
            "2021-05-05 03:41:57 INFO: Loading: tokenize\n",
            "2021-05-05 03:41:57 INFO: Loading: pos\n",
            "2021-05-05 03:41:58 INFO: Loading: lemma\n",
            "2021-05-05 03:41:58 INFO: Done loading processors!\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVwkN_cfV01_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCbcHEsaWGI0"
      },
      "source": [
        "def part3_solver(text, candidate):\n",
        "  possible_answer = []\n",
        "  tokens = []\n",
        "\n",
        "  doc = nlp(text)\n",
        "  for sentence in doc.sentences:\n",
        "    for word in sentence.words:\n",
        "      tokens.append(word.text)\n",
        "  masked_index = tokens.index('*')\n",
        "  tokens[masked_index] = '[MASK]'\n",
        "  tokens = ['[CLS]'] + tokens + ['[SEP]']\n",
        "\n",
        "  print(tokens)\n",
        "\n",
        "  ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "  ids = torch.tensor(ids).reshape(1, -1)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    outputs = model(ids)\n",
        "    # print(outputs)\n",
        "\n",
        "  predictions = outputs[0]\n",
        "\n",
        "\n",
        "  _, predicted_indexes = torch.topk(predictions[0][masked_index+1], k=20)\n",
        "  predicted_tokens = tokenizer.convert_ids_to_tokens(predicted_indexes.tolist())\n",
        "\n",
        "  possible_answer.append(predicted_tokens)\n",
        "  print(possible_answer)\n",
        "  for i, v in enumerate(predicted_tokens):\n",
        "    if v in candidate:\n",
        "      print(i, v)\n",
        "      break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TVId0abonuZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5bjbDF8qlVW"
      },
      "source": [
        "### H20（ア）\n",
        "→正解"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NTA4mx2Tm3y",
        "outputId": "a50fd85f-b708-4b1b-8f8d-edf974bea722"
      },
      "source": [
        "text = \"New computers are * in our English class.\"\n",
        "candidate = ['use', 'uses', 'using', 'used']\n",
        "# 解答used\n",
        "part3_solver(text, candidate)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['[CLS]', 'New', 'computers', 'are', '[MASK]', 'in', 'our', 'English', 'class', '.', '[SEP]']\n",
            "[['not', 'included', 'used', 'available', 'also', 'now', 'located', 'taught', 'only', 'all', 'always', 'here', 'class', 'currently', 'placed', 'found', 'present', 'listed', 'classes', 'still']]\n",
            "2 used\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VI19qvc6qrQX"
      },
      "source": [
        "### H16 （ア）\n",
        "→正解"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CT0Q-62hpxaO",
        "outputId": "8fc67892-feef-498c-bd62-4071248ae3ca"
      },
      "source": [
        "text = \"There are a * desks in the room.\"\n",
        "candidate = ['few', 'little', 'many', 'lot']\n",
        "# 解答 few\n",
        "part3_solver(text, candidate)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['[CLS]', 'There', 'are', 'a', '[MASK]', 'desks', 'in', 'the', 'room', '.', '[SEP]']\n",
            "[['few', 'number', 'small', 'couple', 'single', '[UNK]', 'little', 'thousand', '.', 'constant', 'hundred', 'letter', 'lot', 'large', 'different', 'character', 'and', 'double', '-', 'big']]\n",
            "0 few\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VyCqRZP8qypC"
      },
      "source": [
        "### H14（イ）\n",
        "→正解"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0YGuAPXrqFR2",
        "outputId": "5e949700-2843-4587-934c-5df6b00fc66e"
      },
      "source": [
        "text = \"Many places in Japan have a * season called tsuyu which comes before summer. It may not be a good season for traveling.\"\n",
        "candidate = ['holiday', 'baseball', 'rainy', 'right']\n",
        "# 解答 rainy\n",
        "part3_solver(text, candidate)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['[CLS]', 'Many', 'places', 'in', 'Japan', 'have', 'a', '[MASK]', 'season', 'called', 'tsuyu', 'which', 'comes', 'before', 'summer', '.', 'It', 'may', 'not', 'be', 'a', 'good', 'season', 'for', 'traveling', '.', '[SEP]']\n",
            "[['dry', 'rainy', 'summer', 'long', 'hot', 'winter', 'special', 'good', 'seasonal', 'cold', 'busy', 'short', 'warm', 'cool', 'new', 'wet', 'bad', 'spring', 'different', 'monsoon']]\n",
            "1 rainy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zV8bpS6Vq6Gt"
      },
      "source": [
        "### H28（エ）\n",
        "→不正解  \n",
        "２単語以上の予測はできない。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvqftP_bqjkF",
        "outputId": "cd2b6f7b-13d4-49d4-cfd4-3b4763a93b1c"
      },
      "source": [
        "text = \"The food that you bought yesterday * in a week.\"\n",
        "candidate = ['should eat', 'should be eaten', 'has to eat', 'has eaten']\n",
        "# 解答 should be eaten\n",
        "part3_solver(text, candidate)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['[CLS]', 'The', 'food', 'that', 'you', 'bought', 'yesterday', '[MASK]', 'in', 'a', 'week', '.', '[SEP]']\n",
            "[['and', ',', 'morning', 'or', '.', '...', 'once', 'twice', '##s', '-', 'back', 'afternoon', 'is', 'was', 'came', '?', 'day', 'but', 'maybe', 'sometime']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FVl3W8srT_T"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}